AWSTemplateFormatVersion: '2010-09-09'
Description: 'Complete Spark Code Interpreter Stack - Stable us-east-1 Deployment'

Parameters:
  Environment:
    Type: String
    Default: dev
    AllowedValues:
      - dev
      - prod
    Description: Environment name
  
  BedrockModel:
    Type: String
    Default: us.anthropic.claude-haiku-4-5-20251001-v1:0
    Description: Bedrock model ID for agents
  
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID for EMR and Lambda
  
  PrivateSubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Private subnet IDs for EMR (minimum 2)
  
  PublicSubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Public subnet IDs for ALB (minimum 2)

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Environment Configuration
        Parameters:
          - Environment
          - BedrockModel
      - Label:
          default: Network Configuration
        Parameters:
          - VpcId
          - PrivateSubnetIds
          - PublicSubnetIds

Resources:
  # ============================================================================
  # S3 Bucket for Spark Data
  # ============================================================================
  SparkDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub 'spark-data-${AWS::AccountId}-${AWS::Region}'
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldOutputs
            Status: Enabled
            ExpirationInDays: 30
            Prefix: output/
          - Id: DeleteOldLogs
            Status: Enabled
            ExpirationInDays: 7
            Prefix: logs/
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: SparkData

  # ============================================================================
  # IAM Roles
  # ============================================================================
  
  # Lambda Execution Role
  SparkLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${Environment}-spark-lambda-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: SparkLambdaPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt SparkDataBucket.Arn
                  - !Sub '${SparkDataBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - glue:GetDatabase
                  - glue:GetTable
                  - glue:GetPartitions
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  # EMR Serverless Execution Role
  EMRExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${Environment}-spark-emr-execution-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: emr-serverless.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: EMRExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt SparkDataBucket.Arn
                  - !Sub '${SparkDataBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - glue:GetDatabase
                  - glue:GetTable
                  - glue:GetPartitions
                  - glue:CreateTable
                  - glue:UpdateTable
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  # Backend Lambda Role
  BackendLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${Environment}-spark-supervisor-lambda-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: BackendLambdaPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock-agentcore:InvokeAgentRuntime
                Resource: '*'
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource: !GetAtt SparkOnLambda.Arn
              - Effect: Allow
                Action:
                  - emr-serverless:StartJobRun
                  - emr-serverless:GetJobRun
                  - emr-serverless:CancelJobRun
                  - emr-serverless:ListJobRuns
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt SparkDataBucket.Arn
                  - !Sub '${SparkDataBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  # AgentCore Runtime Role
  AgentCoreRuntimeRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'AmazonBedrockAgentCoreSDKRuntime-${AWS::Region}-${Environment}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: bedrock-agentcore.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonBedrockFullAccess
      Policies:
        - PolicyName: AgentCoreRuntimePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                Resource: '*'
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource: !GetAtt SparkOnLambda.Arn
              - Effect: Allow
                Action:
                  - emr-serverless:StartJobRun
                  - emr-serverless:GetJobRun
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt SparkDataBucket.Arn
                  - !Sub '${SparkDataBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - glue:GetDatabase
                  - glue:GetTable
                  - glue:GetPartitions
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  # ============================================================================
  # Lambda Functions
  # ============================================================================
  
  SparkOnLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${Environment}-spark-on-lambda'
      Runtime: python3.11
      Handler: index.handler
      Role: !GetAtt SparkLambdaRole.Arn
      Timeout: 300
      MemorySize: 3008
      Environment:
        Variables:
          S3_BUCKET: !Ref SparkDataBucket
      Code:
        ZipFile: |
          import json
          def handler(event, context):
              return {
                  'statusCode': 200,
                  'body': json.dumps({'message': 'Placeholder - deploy actual code'})
              }
      Tags:
        - Key: Environment
          Value: !Ref Environment

  # ============================================================================
  # EMR Serverless Application
  # ============================================================================
  
  EMRServerlessApplication:
    Type: AWS::EMRServerless::Application
    Properties:
      Name: !Sub '${Environment}-spark-emr'
      ReleaseLabel: emr-6.15.0
      Type: Spark
      MaximumCapacity:
        Cpu: 100 vCPU
        Memory: 200 GB
        Disk: 400000 GB
      AutoStartConfiguration:
        Enabled: true
      AutoStopConfiguration:
        Enabled: true
        IdleTimeoutMinutes: 15
      NetworkConfiguration:
        SubnetIds: !Ref PrivateSubnetIds
      Tags:
        - Key: Environment
          Value: !Ref Environment

  # ============================================================================
  # Application Load Balancer
  # ============================================================================
  
  ALBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub '${Environment}-spark-alb-sg'
      GroupDescription: Security group for Spark ALB
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
          Description: HTTPS from anywhere
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
          Description: HTTP from anywhere
      Tags:
        - Key: Environment
          Value: !Ref Environment

  ApplicationLoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub '${Environment}-spark-alb'
      Type: application
      Scheme: internet-facing
      IpAddressType: ipv4
      Subnets: !Ref PublicSubnetIds
      SecurityGroups:
        - !Ref ALBSecurityGroup
      Tags:
        - Key: Environment
          Value: !Ref Environment

  ALBTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub '${Environment}-spark-backend-tg'
      Port: 8000
      Protocol: HTTP
      VpcId: !Ref VpcId
      TargetType: lambda
      HealthCheckEnabled: true
      HealthCheckPath: /health
      HealthCheckIntervalSeconds: 30
      HealthCheckTimeoutSeconds: 5
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 2
      Matcher:
        HttpCode: 200
      Tags:
        - Key: Environment
          Value: !Ref Environment

  ALBListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      LoadBalancerArn: !Ref ApplicationLoadBalancer
      Port: 80
      Protocol: HTTP
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref ALBTargetGroup

Outputs:
  SparkDataBucketName:
    Description: S3 bucket for Spark data
    Value: !Ref SparkDataBucket
    Export:
      Name: !Sub '${Environment}-SparkDataBucket'
  
  SparkLambdaFunctionName:
    Description: Spark Lambda function name
    Value: !Ref SparkOnLambda
    Export:
      Name: !Sub '${Environment}-SparkLambdaFunction'
  
  SparkLambdaFunctionArn:
    Description: Spark Lambda function ARN
    Value: !GetAtt SparkOnLambda.Arn
    Export:
      Name: !Sub '${Environment}-SparkLambdaArn'
  
  EMRApplicationId:
    Description: EMR Serverless application ID
    Value: !Ref EMRServerlessApplication
    Export:
      Name: !Sub '${Environment}-EMRApplicationId'
  
  EMRExecutionRoleArn:
    Description: EMR execution role ARN
    Value: !GetAtt EMRExecutionRole.Arn
    Export:
      Name: !Sub '${Environment}-EMRExecutionRoleArn'
  
  ALBDNSName:
    Description: ALB DNS name
    Value: !GetAtt ApplicationLoadBalancer.DNSName
    Export:
      Name: !Sub '${Environment}-ALBDNSName'
  
  ALBUrl:
    Description: ALB URL
    Value: !Sub 'http://${ApplicationLoadBalancer.DNSName}'
    Export:
      Name: !Sub '${Environment}-ALBUrl'
  
  AgentCoreRuntimeRoleArn:
    Description: AgentCore runtime role ARN
    Value: !GetAtt AgentCoreRuntimeRole.Arn
    Export:
      Name: !Sub '${Environment}-AgentCoreRuntimeRoleArn'
